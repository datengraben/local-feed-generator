# Official language image. Look for the different tagged releases at:
# https://hub.docker.com/r/library/python/tags/
image: python:3.10-bookworm

# Change pip's cache directory to be inside the project directory since we can
# only cache local items.
variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"

# https://pip.pypa.io/en/stable/topics/caching/
cache:
  paths:
    - .cache/pip

before_script:
# Set the locale
  - apt-get update && apt-get install -y locales locales-all
  - dpkg-reconfigure locales
  - export LC_ALL=de_DE.UTF-8
  - export LANG=de_DE.UTF-8 
  - dpkg-reconfigure locales
  - python --version ; pip --version  # For debugging
  - pip install virtualenv
  - virtualenv venv
  - source venv/bin/activate


stages:          # List of stages for jobs, and their order of execution
  - build
  - test
  - deploy

scrape-job:       # This job runs in the build stage, which runs first.
  stage: build
  script:
    - pip install -r requirements.txt 
    - apt-get update && apt-get install libxml2-utils
    - sh run.sh

validate-rss-job:   # This job runs in the test stage.
  stage: test    # It only starts when the job in the build stage completes successfully.
  script:
    - | 
      git config user.name "Automated"
      git config user.email "actions@noreply.git.datengraben.com"
      git remote add gitlab_origin https://oauth2:$APPLICATION_TOKEN@git.shannes.de/events-scraper.git 
      git add atom.xml
      timestamp=$(date -u)
      git commit -m "Latest data: ${timestamp}" || exit 0
      git push gitlab_origin HEAD:master -o ci.skip # prevent triggering pipeline again 


deploy-to-http-job:      # This job runs in the deploy stage.
  stage: deploy  # It only runs when *both* jobs in the test stage complete successfully.
#  environment: production
  script:
    - sh deploy.sh
